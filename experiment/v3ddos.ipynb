{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the script uses binarization strategies for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:34:28.160622Z",
     "iopub.status.busy": "2025-03-30T07:34:28.160392Z",
     "iopub.status.idle": "2025-03-30T07:34:37.634582Z",
     "shell.execute_reply": "2025-03-30T07:34:37.633838Z",
     "shell.execute_reply.started": "2025-03-30T07:34:28.160601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyTsetlinMachine\n",
      "  Downloading pyTsetlinMachine-0.6.6.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (19.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\n",
      "Building wheels for collected packages: pyTsetlinMachine\n",
      "  Building wheel for pyTsetlinMachine (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyTsetlinMachine: filename=pyTsetlinMachine-0.6.6-cp310-cp310-linux_x86_64.whl size=59504 sha256=0d520e9e53cdd1f0cbb5e258befa8582fc1f6b38b0d06c14a172b02ebd84dc4c\n",
      "  Stored in directory: /root/.cache/pip/wheels/b0/b0/c5/07c4cb8bb93c5325bdc2c2a070b565f54df717d5d11f0c6802\n",
      "Successfully built pyTsetlinMachine\n",
      "Installing collected packages: pyTsetlinMachine\n",
      "Successfully installed pyTsetlinMachine-0.6.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pyTsetlinMachine pandas scikit-learn pyarrow matplotlib seaborn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from pyTsetlinMachine.tm import MultiClassTsetlinMachine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source of training dataset:\n",
    "\n",
    "https://ieeexplore.ieee.org/abstract/document/8888419\n",
    "\n",
    "https://www.kaggle.com/datasets/dhoogla/cicddos2019\n",
    "\n",
    "\n",
    "(for preliminary testing, the test-train split in this dataset has been used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:34:49.669283Z",
     "iopub.status.busy": "2025-03-30T07:34:49.668983Z",
     "iopub.status.idle": "2025-03-30T07:34:53.335277Z",
     "shell.execute_reply": "2025-03-30T07:34:53.334358Z",
     "shell.execute_reply.started": "2025-03-30T07:34:49.669261Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete! Ready for model training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "data_dir = \"/kaggle/input/cicddos2019\"\n",
    "training_files = glob.glob(os.path.join(data_dir, \"*-training.parquet\"))\n",
    "testing_files = glob.glob(os.path.join(data_dir, \"*-testing.parquet\"))\n",
    "\n",
    "if not training_files:\n",
    "    print(\" No training files found!\")\n",
    "if not testing_files:\n",
    "    print(\" No testing files found!\")\n",
    "\n",
    "train_data = pd.concat([pd.read_parquet(f) for f in training_files], ignore_index=True)\n",
    "test_data = pd.concat([pd.read_parquet(f) for f in testing_files], ignore_index=True)\n",
    "\n",
    "ddos_types = [\"DrDoS_DNS\", \"DrDoS_LDAP\", \"DrDoS_MSSQL\", \"DrDoS_NTP\", \"DrDoS_NetBIOS\", \n",
    "              \"DrDoS_SNMP\", \"Syn\", \"TFTP\", \"UDP\", \"UDPLag\"]\n",
    "label_mapping = {attack.upper(): 1 for attack in ddos_types}\n",
    "label_mapping[\"BENIGN\"] = 0\n",
    "\n",
    "train_data['Label'] = train_data['Label'].str.upper()\n",
    "test_data['Label'] = test_data['Label'].str.upper()\n",
    "\n",
    "train_data = train_data[train_data['Label'].isin(label_mapping)]\n",
    "test_data = test_data[test_data['Label'].isin(label_mapping)]\n",
    "train_data['Label'] = train_data['Label'].map(label_mapping)\n",
    "test_data['Label'] = test_data['Label'].map(label_mapping)\n",
    "\n",
    "train_data.fillna(train_data.median(numeric_only=True), inplace=True)\n",
    "test_data.fillna(test_data.median(numeric_only=True), inplace=True)\n",
    "\n",
    "drop_features = [\n",
    "    \"Fwd Packet Length Max\", \"Bwd Packet Length Max\", \"Packet Length Max\", \"Subflow Fwd Bytes\",\n",
    "    \"Subflow Bwd Bytes\", \"Init Bwd Win Bytes\", \"Flow Bytes/s\", \"Fwd IAT Total\", \"Bwd IAT Total\", \n",
    "    \"Avg Packet Size\", \"Fwd Packets Length Total\", \"Bwd Packets Length Total\"\n",
    "]\n",
    "existing_drop_features = [col for col in drop_features if col in train_data.columns]\n",
    "train_data.drop(columns=existing_drop_features, inplace=True)\n",
    "test_data.drop(columns=existing_drop_features, inplace=True)\n",
    "\n",
    "categorical_features = ['Protocol']\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_train = one_hot_encoder.fit_transform(train_data[categorical_features])\n",
    "encoded_test = one_hot_encoder.transform(test_data[categorical_features])\n",
    "\n",
    "encoded_columns = one_hot_encoder.get_feature_names_out(categorical_features)\n",
    "train_encoded_df = pd.DataFrame(encoded_train, columns=encoded_columns, index=train_data.index)\n",
    "test_encoded_df = pd.DataFrame(encoded_test, columns=encoded_columns, index=test_data.index)\n",
    "\n",
    "train_data = pd.concat([train_data.drop(columns=categorical_features), train_encoded_df], axis=1)\n",
    "test_data = pd.concat([test_data.drop(columns=categorical_features), test_encoded_df], axis=1)\n",
    "\n",
    "binary_flags = [\"Fwd PSH Flags\", \"Bwd PSH Flags\", \"Fwd URG Flags\", \"Bwd URG Flags\"]\n",
    "for flag in binary_flags:\n",
    "    if flag in train_data.columns:\n",
    "        train_data[flag] = (train_data[flag] > 0).astype(int)\n",
    "        test_data[flag] = (test_data[flag] > 0).astype(int)\n",
    "\n",
    "continuous_features = [\n",
    "    \"Flow Duration\", \"Fwd Packet Length Mean\", \"Bwd Packet Length Mean\", \"Packet Length Mean\",\n",
    "    \"Flow IAT Mean\", \"Flow IAT Std\", \"Fwd IAT Mean\", \"Bwd IAT Mean\", \"Active Mean\", \"Idle Mean\"\n",
    "]\n",
    "for feature in continuous_features:\n",
    "    if feature in train_data.columns:\n",
    "        q1, q2, q3 = np.percentile(train_data[feature], [25, 50, 75])\n",
    "        train_data[f\"{feature}_bin1\"] = (train_data[feature] <= q1).astype(int)\n",
    "        train_data[f\"{feature}_bin2\"] = ((train_data[feature] > q1) & (train_data[feature] <= q2)).astype(int)\n",
    "        train_data[f\"{feature}_bin3\"] = ((train_data[feature] > q2) & (train_data[feature] <= q3)).astype(int)\n",
    "        train_data[f\"{feature}_bin4\"] = (train_data[feature] > q3).astype(int)\n",
    "        \n",
    "        test_data[f\"{feature}_bin1\"] = (test_data[feature] <= q1).astype(int)\n",
    "        test_data[f\"{feature}_bin2\"] = ((test_data[feature] > q1) & (test_data[feature] <= q2)).astype(int)\n",
    "        test_data[f\"{feature}_bin3\"] = ((test_data[feature] > q2) & (test_data[feature] <= q3)).astype(int)\n",
    "        test_data[f\"{feature}_bin4\"] = (test_data[feature] > q3).astype(int)\n",
    "        \n",
    "    train_data.drop(columns=[feature], inplace=True)\n",
    "    test_data.drop(columns=[feature], inplace=True)\n",
    "\n",
    "X_train = train_data.drop(columns=['Label'])\n",
    "y_train = train_data['Label']\n",
    "X_test = test_data.drop(columns=['Label'])\n",
    "y_test = test_data['Label']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Preprocessing complete! Ready for model training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:34:56.713072Z",
     "iopub.status.busy": "2025-03-30T07:34:56.712779Z",
     "iopub.status.idle": "2025-03-30T07:34:56.753343Z",
     "shell.execute_reply": "2025-03-30T07:34:56.752540Z",
     "shell.execute_reply.started": "2025-03-30T07:34:56.713051Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of features used for training: 97\n",
      "Features:\n",
      "- Total Fwd Packets\n",
      "- Total Backward Packets\n",
      "- Fwd Packet Length Min\n",
      "- Fwd Packet Length Std\n",
      "- Bwd Packet Length Min\n",
      "- Bwd Packet Length Std\n",
      "- Flow Packets/s\n",
      "- Flow IAT Max\n",
      "- Flow IAT Min\n",
      "- Fwd IAT Std\n",
      "- Fwd IAT Max\n",
      "- Fwd IAT Min\n",
      "- Bwd IAT Std\n",
      "- Bwd IAT Max\n",
      "- Bwd IAT Min\n",
      "- Fwd PSH Flags\n",
      "- Bwd PSH Flags\n",
      "- Fwd URG Flags\n",
      "- Bwd URG Flags\n",
      "- Fwd Header Length\n",
      "- Bwd Header Length\n",
      "- Fwd Packets/s\n",
      "- Bwd Packets/s\n",
      "- Packet Length Min\n",
      "- Packet Length Std\n",
      "- Packet Length Variance\n",
      "- FIN Flag Count\n",
      "- SYN Flag Count\n",
      "- RST Flag Count\n",
      "- PSH Flag Count\n",
      "- ACK Flag Count\n",
      "- URG Flag Count\n",
      "- CWE Flag Count\n",
      "- ECE Flag Count\n",
      "- Down/Up Ratio\n",
      "- Avg Fwd Segment Size\n",
      "- Avg Bwd Segment Size\n",
      "- Fwd Avg Bytes/Bulk\n",
      "- Fwd Avg Packets/Bulk\n",
      "- Fwd Avg Bulk Rate\n",
      "- Bwd Avg Bytes/Bulk\n",
      "- Bwd Avg Packets/Bulk\n",
      "- Bwd Avg Bulk Rate\n",
      "- Subflow Fwd Packets\n",
      "- Subflow Bwd Packets\n",
      "- Init Fwd Win Bytes\n",
      "- Fwd Act Data Packets\n",
      "- Fwd Seg Size Min\n",
      "- Active Std\n",
      "- Active Max\n",
      "- Active Min\n",
      "- Idle Std\n",
      "- Idle Max\n",
      "- Idle Min\n",
      "- Protocol_0\n",
      "- Protocol_6\n",
      "- Protocol_17\n",
      "- Flow Duration_bin1\n",
      "- Flow Duration_bin2\n",
      "- Flow Duration_bin3\n",
      "- Flow Duration_bin4\n",
      "- Fwd Packet Length Mean_bin1\n",
      "- Fwd Packet Length Mean_bin2\n",
      "- Fwd Packet Length Mean_bin3\n",
      "- Fwd Packet Length Mean_bin4\n",
      "- Bwd Packet Length Mean_bin1\n",
      "- Bwd Packet Length Mean_bin2\n",
      "- Bwd Packet Length Mean_bin3\n",
      "- Bwd Packet Length Mean_bin4\n",
      "- Packet Length Mean_bin1\n",
      "- Packet Length Mean_bin2\n",
      "- Packet Length Mean_bin3\n",
      "- Packet Length Mean_bin4\n",
      "- Flow IAT Mean_bin1\n",
      "- Flow IAT Mean_bin2\n",
      "- Flow IAT Mean_bin3\n",
      "- Flow IAT Mean_bin4\n",
      "- Flow IAT Std_bin1\n",
      "- Flow IAT Std_bin2\n",
      "- Flow IAT Std_bin3\n",
      "- Flow IAT Std_bin4\n",
      "- Fwd IAT Mean_bin1\n",
      "- Fwd IAT Mean_bin2\n",
      "- Fwd IAT Mean_bin3\n",
      "- Fwd IAT Mean_bin4\n",
      "- Bwd IAT Mean_bin1\n",
      "- Bwd IAT Mean_bin2\n",
      "- Bwd IAT Mean_bin3\n",
      "- Bwd IAT Mean_bin4\n",
      "- Active Mean_bin1\n",
      "- Active Mean_bin2\n",
      "- Active Mean_bin3\n",
      "- Active Mean_bin4\n",
      "- Idle Mean_bin1\n",
      "- Idle Mean_bin2\n",
      "- Idle Mean_bin3\n",
      "- Idle Mean_bin4\n"
     ]
    }
   ],
   "source": [
    "final_feature_names = train_data.drop(columns=['Label']).columns.tolist()\n",
    "\n",
    "print(f\"Final number of features used for training: {len(final_feature_names)}\")\n",
    "print(\"Features:\")\n",
    "for feature in final_feature_names:\n",
    "    print(f\"- {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:35:01.293923Z",
     "iopub.status.busy": "2025-03-30T07:35:01.293563Z",
     "iopub.status.idle": "2025-03-30T07:35:06.672768Z",
     "shell.execute_reply": "2025-03-30T07:35:06.671850Z",
     "shell.execute_reply.started": "2025-03-30T07:35:01.293896Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Selected 53 features for training.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "feature_names = train_data.drop(columns=['Label']).columns  # Get feature names before scaling\n",
    "X_train = pd.DataFrame(X_train, columns=feature_names)  # Convert back to DataFrame\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "feature_importance_dict = {feature: importance for feature, importance in zip(X_train.columns, feature_importances)}\n",
    "\n",
    "# grouping binned features together\n",
    "bin_feature_groups = {}  \n",
    "for feature in X_train.columns:\n",
    "    if \"_bin\" in feature: \n",
    "        base_feature = \"_\".join(feature.split(\"_\")[:-1])  \n",
    "        bin_feature_groups.setdefault(base_feature, []).append(feature)\n",
    "\n",
    "# summing importance values for each base feature\n",
    "base_feature_importance = {}\n",
    "for base_feature, bins in bin_feature_groups.items():\n",
    "    total_importance = sum(feature_importance_dict[bin] for bin in bins)\n",
    "    base_feature_importance[base_feature] = total_importance\n",
    "    for bin in bins:\n",
    "        feature_importance_dict[bin] = total_importance  \n",
    "\n",
    "# sorting features by importance (bins have been grouped under the same score)\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# choosing the top features (to make sure that all bins of a feature are included)\n",
    "num_features_to_keep = 50\n",
    "selected_features = set()\n",
    "\n",
    "for feature, _ in sorted_features:\n",
    "    if \"_bin\" in feature:  # If it's a binned feature\n",
    "        base_feature = \"_\".join(feature.split(\"_\")[:-1])\n",
    "        if base_feature not in selected_features:\n",
    "            selected_features.update(bin_feature_groups[base_feature])  # Add all bins\n",
    "    else:\n",
    "        selected_features.add(feature)\n",
    "    if len(selected_features) >= num_features_to_keep:\n",
    "        break\n",
    "\n",
    "# filtering the dataset based on selected features\n",
    "selected_features = list(selected_features)\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features for training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:35:14.237698Z",
     "iopub.status.busy": "2025-03-30T07:35:14.237334Z",
     "iopub.status.idle": "2025-03-30T07:35:14.248469Z",
     "shell.execute_reply": "2025-03-30T07:35:14.245499Z",
     "shell.execute_reply.started": "2025-03-30T07:35:14.237672Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final selected features (53):\n",
      "1. Avg Bwd Segment Size\n",
      "2. Bwd Packet Length Mean_bin4\n",
      "3. Active Min\n",
      "4. Flow Duration_bin3\n",
      "5. Idle Max\n",
      "6. Total Backward Packets\n",
      "7. Total Fwd Packets\n",
      "8. Fwd Packet Length Std\n",
      "9. Fwd IAT Mean_bin3\n",
      "10. Fwd Packet Length Mean_bin4\n",
      "11. Down/Up Ratio\n",
      "12. Fwd Packet Length Mean_bin2\n",
      "13. Packet Length Min\n",
      "14. Fwd IAT Mean_bin1\n",
      "15. Flow IAT Max\n",
      "16. Idle Std\n",
      "17. Fwd Packets/s\n",
      "18. CWE Flag Count\n",
      "19. Bwd Packet Length Mean_bin1\n",
      "20. Fwd Packet Length Min\n",
      "21. Avg Fwd Segment Size\n",
      "22. Flow Packets/s\n",
      "23. Flow Duration_bin4\n",
      "24. Fwd IAT Max\n",
      "25. Flow IAT Mean_bin1\n",
      "26. Subflow Bwd Packets\n",
      "27. Flow Duration_bin1\n",
      "28. Packet Length Mean_bin2\n",
      "29. Packet Length Std\n",
      "30. Flow IAT Mean_bin2\n",
      "31. Packet Length Variance\n",
      "32. ACK Flag Count\n",
      "33. Fwd IAT Mean_bin4\n",
      "34. Fwd IAT Std\n",
      "35. Packet Length Mean_bin1\n",
      "36. Init Fwd Win Bytes\n",
      "37. Fwd Act Data Packets\n",
      "38. Fwd IAT Mean_bin2\n",
      "39. Bwd Packet Length Min\n",
      "40. Flow Duration_bin2\n",
      "41. Flow IAT Mean_bin3\n",
      "42. RST Flag Count\n",
      "43. Packet Length Mean_bin4\n",
      "44. URG Flag Count\n",
      "45. Packet Length Mean_bin3\n",
      "46. Bwd Packet Length Std\n",
      "47. Subflow Fwd Packets\n",
      "48. Fwd Packet Length Mean_bin3\n",
      "49. Bwd Packets/s\n",
      "50. Flow IAT Mean_bin4\n",
      "51. Bwd Packet Length Mean_bin2\n",
      "52. Bwd Packet Length Mean_bin3\n",
      "53. Fwd Packet Length Mean_bin1\n"
     ]
    }
   ],
   "source": [
    "print(\"Final selected features (53):\")\n",
    "for i, feature in enumerate(selected_features, 1):\n",
    "    print(f\"{i}. {feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:35:33.083152Z",
     "iopub.status.busy": "2025-03-30T07:35:33.082859Z",
     "iopub.status.idle": "2025-03-30T07:35:33.181365Z",
     "shell.execute_reply": "2025-03-30T07:35:33.180650Z",
     "shell.execute_reply.started": "2025-03-30T07:35:33.083131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features reordered. Final column order in X_train:\n",
      "['Flow Duration_bin1', 'Flow Duration_bin2', 'Flow Duration_bin3', 'Flow Duration_bin4', 'Fwd Packet Length Mean_bin1', 'Fwd Packet Length Mean_bin2', 'Fwd Packet Length Mean_bin3', 'Fwd Packet Length Mean_bin4', 'Bwd Packet Length Mean_bin1', 'Bwd Packet Length Mean_bin2', 'Bwd Packet Length Mean_bin3', 'Bwd Packet Length Mean_bin4', 'Packet Length Mean_bin1', 'Packet Length Mean_bin2', 'Packet Length Mean_bin3', 'Packet Length Mean_bin4', 'Flow IAT Mean_bin1', 'Flow IAT Mean_bin2', 'Flow IAT Mean_bin3', 'Flow IAT Mean_bin4', 'Flow IAT Std_bin1', 'Flow IAT Std_bin2', 'Flow IAT Std_bin3', 'Flow IAT Std_bin4', 'Fwd IAT Mean_bin1', 'Fwd IAT Mean_bin2', 'Fwd IAT Mean_bin3', 'Fwd IAT Mean_bin4', 'Bwd IAT Mean_bin1', 'Bwd IAT Mean_bin2', 'Bwd IAT Mean_bin3', 'Bwd IAT Mean_bin4', 'Active Mean_bin1', 'Active Mean_bin2', 'Active Mean_bin3', 'Active Mean_bin4', 'Idle Mean_bin1', 'Idle Mean_bin2', 'Idle Mean_bin3', 'Idle Mean_bin4', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packet Length Min', 'Fwd Packet Length Std', 'Bwd Packet Length Min', 'Bwd Packet Length Std', 'Flow Packets/s', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Bwd Packets', 'Init Fwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Std', 'Active Max', 'Active Min', 'Idle Std', 'Idle Max', 'Idle Min', 'Protocol_0', 'Protocol_6', 'Protocol_17']\n"
     ]
    }
   ],
   "source": [
    "bin_feature_groups = {} \n",
    "other_features = []  \n",
    "\n",
    "for feature in X_train.columns:\n",
    "    if \"_bin\" in feature:  \n",
    "        base_feature = \"_\".join(feature.split(\"_\")[:-1]) \n",
    "        bin_feature_groups.setdefault(base_feature, []).append(feature)\n",
    "    else:\n",
    "        other_features.append(feature)  \n",
    "\n",
    "sorted_feature_order = []\n",
    "\n",
    "for base_feature, bins in bin_feature_groups.items():\n",
    "    sorted_feature_order.extend(sorted(bins))  \n",
    "\n",
    "sorted_feature_order.extend(other_features)\n",
    "\n",
    "X_train = X_train[sorted_feature_order]\n",
    "X_test = X_test[sorted_feature_order]\n",
    "\n",
    "print(\"✅ Features reordered. Final column order in X_train:\")\n",
    "print(X_train.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:35:38.778313Z",
     "iopub.status.busy": "2025-03-30T07:35:38.778011Z",
     "iopub.status.idle": "2025-03-30T07:35:38.786240Z",
     "shell.execute_reply": "2025-03-30T07:35:38.785278Z",
     "shell.execute_reply.started": "2025-03-30T07:35:38.778291Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 113412\n",
      "Training set label distribution:\n",
      " Label\n",
      "1    66985\n",
      "0    46427\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total training samples: {len(train_data)}\")\n",
    "\n",
    "print(\"Training set label distribution:\\n\", train_data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:35:40.827075Z",
     "iopub.status.busy": "2025-03-30T07:35:40.826783Z",
     "iopub.status.idle": "2025-03-30T07:35:40.832340Z",
     "shell.execute_reply": "2025-03-30T07:35:40.831507Z",
     "shell.execute_reply.started": "2025-03-30T07:35:40.827054Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (113412, 97)\n",
      "X_test shape: (286858, 97)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)  \n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:35:42.491687Z",
     "iopub.status.busy": "2025-03-30T07:35:42.491327Z",
     "iopub.status.idle": "2025-03-30T07:35:42.496284Z",
     "shell.execute_reply": "2025-03-30T07:35:42.495511Z",
     "shell.execute_reply.started": "2025-03-30T07:35:42.491662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (113412,)\n",
      "X_test shape: (286858,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", y_train.shape)  \n",
    "print(\"X_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get statistically significant results, \n",
    "probably need to use the same training script multiple times, find a different best model each time, and find its perofrmance on test dataset each time, then take average of all of those times for final results.\n",
    "how many tims to do it to make sure it is statistically significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:38:04.648616Z",
     "iopub.status.busy": "2025-03-30T07:38:04.648238Z",
     "iopub.status.idle": "2025-03-30T07:41:25.872992Z",
     "shell.execute_reply": "2025-03-30T07:41:25.871914Z",
     "shell.execute_reply.started": "2025-03-30T07:38:04.648583Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Testing params: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Testing params: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Testing params: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Testing params: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Testing params: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Testing params: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Testing params: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "\n",
      " Training final model with best params: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      " Test Set Performance (Random Forest):\n",
      " Accuracy: 0.8413\n",
      " Precision: 0.9997\n",
      " Recall: 0.8069\n",
      " F1 Score: 0.8930\n",
      "\n",
      " Confusion Matrix:\n",
      " [[ 51354     50]\n",
      " [ 45469 189985]]\n",
      "\n",
      " Inference Time: 0.934096 seconds\n",
      " Peak Memory Usage: 91753.24 KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tracemalloc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "X_train_selected = X_train_selected.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test_selected = X_test_selected.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "param_grid = {'n_estimators': [100, 200], 'max_depth': [10, 20], 'min_samples_split': [2, 5]}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_params, best_f1, lowest_fpr, best_model = None, 0, float('inf'), None\n",
    "\n",
    "def train_fold(n_estimators, max_depth, min_samples_split, X_train_fold, y_train_fold, X_val_fold, y_val_fold):\n",
    "    \"\"\"Train Random Forest on a single fold.\"\"\"\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    f1 = f1_score(y_val_fold, y_val_pred, zero_division=0)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    return accuracy_score(y_val_fold, y_val_pred), f1, fpr\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing params: {params}\")\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(train_fold)(\n",
    "            params['n_estimators'], params['max_depth'], params['min_samples_split'],\n",
    "            X_train_selected.iloc[train], y_train.iloc[train],  # Using `.iloc` to ensure proper slicing\n",
    "            X_train_selected.iloc[val], y_train.iloc[val]\n",
    "        ) for train, val in kf.split(X_train_selected)\n",
    "    )\n",
    "    \n",
    "    mean_acc, mean_f1, mean_fpr = np.mean(results, axis=0)\n",
    "    if mean_f1 > best_f1 or (mean_f1 == best_f1 and mean_fpr < lowest_fpr):\n",
    "        best_f1, lowest_fpr, best_params = mean_f1, mean_fpr, params\n",
    "\n",
    "        with open(\"/kaggle/working/best_params_rf.pkl\", \"wb\") as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "if best_params:\n",
    "    print(f\"\\n Training final model with best params: {best_params}\")\n",
    "    best_model = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)\n",
    "    best_model.fit(X_train_selected, y_train)\n",
    "\n",
    "    with open(\"/kaggle/working/best_model_rf.pkl\", \"wb\") as model_file:\n",
    "        pickle.dump(best_model, model_file)\n",
    "\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    y_test_pred = best_model.predict(X_test_selected)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    inference_time = end_time - start_time\n",
    "    peak_memory_kb = peak / 1024  \n",
    "\n",
    "    print(\"\\n Test Set Performance (Random Forest):\")\n",
    "    print(f\" Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\" Precision: {precision_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "    print(f\" Recall: {recall_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "    print(f\" F1 Score: {f1_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "    print(\"\\n Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "    \n",
    "    print(f\"\\n Inference Time: {inference_time:.6f} seconds\")\n",
    "    print(f\" Peak Memory Usage: {peak_memory_kb:.2f} KB\")\n",
    "\n",
    "else:\n",
    "    print(\"No trained model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:16.238927Z",
     "iopub.status.busy": "2025-03-30T07:57:16.238534Z",
     "iopub.status.idle": "2025-03-30T08:01:34.789892Z",
     "shell.execute_reply": "2025-03-30T08:01:34.788801Z",
     "shell.execute_reply.started": "2025-03-30T07:57:16.238901Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing params: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      " Testing params: {'n_neighbors': 3, 'weights': 'distance'}\n",
      " Testing params: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      " Testing params: {'n_neighbors': 5, 'weights': 'distance'}\n",
      " Testing params: {'n_neighbors': 7, 'weights': 'uniform'}\n",
      " Testing params: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "\n",
      " Training final model with best params: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "\n",
      " Test Set Performance (KNN):\n",
      "Accuracy:            0.9812\n",
      "Precision:           0.9996\n",
      "Recall:              0.9775\n",
      "F1 Score:            0.9884\n",
      "False Positive Rate: 0.0017\n",
      "\n",
      " Confusion Matrix:\n",
      " [[ 51316     88]\n",
      " [  5294 230160]]\n",
      "\n",
      " Inference Time: 73.439659 seconds\n",
      " Peak Memory Usage: 144503.31 KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tracemalloc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "X_train_selected = X_train_selected.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test_selected = X_test_selected.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "param_grid = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_params, best_f1, lowest_fpr, best_model = None, 0, float('inf'), None\n",
    "\n",
    "def train_fold(n_neighbors, weights, X_train_fold, y_train_fold, X_val_fold, y_val_fold):\n",
    "    \"\"\"Train KNN on a single fold.\"\"\"\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    f1 = f1_score(y_val_fold, y_val_pred, zero_division=0)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    return accuracy_score(y_val_fold, y_val_pred), f1, fpr\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\" Testing params: {params}\")\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(train_fold)(\n",
    "            params['n_neighbors'], params['weights'],\n",
    "            X_train_selected.iloc[train], y_train.iloc[train],  \n",
    "            X_train_selected.iloc[val], y_train.iloc[val]\n",
    "        ) for train, val in kf.split(X_train_selected)\n",
    "    )\n",
    "    \n",
    "    mean_acc, mean_f1, mean_fpr = np.mean(results, axis=0)\n",
    "    if mean_f1 > best_f1 or (mean_f1 == best_f1 and mean_fpr < lowest_fpr):\n",
    "        best_f1, lowest_fpr, best_params = mean_f1, mean_fpr, params\n",
    "\n",
    "        with open(\"/kaggle/working/best_params_knn.pkl\", \"wb\") as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "if best_params:\n",
    "    print(f\"\\n Training final model with best params: {best_params}\")\n",
    "    best_model = KNeighborsClassifier(**best_params)\n",
    "    best_model.fit(X_train_selected, y_train)\n",
    "\n",
    "    with open(\"/kaggle/working/best_model_knn.pkl\", \"wb\") as model_file:\n",
    "        pickle.dump(best_model, model_file)\n",
    "\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    y_test_pred = best_model.predict(X_test_selected)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    inference_time = end_time - start_time\n",
    "    peak_memory_kb = peak / 1024  \n",
    "\n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "    prec = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  \n",
    "\n",
    "    print(\"\\n Test Set Performance (KNN):\")\n",
    "    print(f\"Accuracy:            {acc:.4f}\")\n",
    "    print(f\"Precision:           {prec:.4f}\")\n",
    "    print(f\"Recall:              {rec:.4f}\")\n",
    "    print(f\"F1 Score:            {f1:.4f}\")\n",
    "    print(f\"False Positive Rate: {fpr:.4f}\")\n",
    "    print(\"\\n Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "    \n",
    "    print(f\"\\n Inference Time: {inference_time:.6f} seconds\")\n",
    "    print(f\" Peak Memory Usage: {peak_memory_kb:.2f} KB\")\n",
    "\n",
    "else:\n",
    "    print(\" No trained model found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:02:03.937927Z",
     "iopub.status.busy": "2025-03-30T08:02:03.937597Z",
     "iopub.status.idle": "2025-03-30T08:07:26.588706Z",
     "shell.execute_reply": "2025-03-30T08:07:26.587843Z",
     "shell.execute_reply.started": "2025-03-30T08:02:03.937902Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'C': 1, 'kernel': 'linear'}\n",
      "Testing params: {'C': 1, 'kernel': 'rbf'}\n",
      "Testing params: {'C': 10, 'kernel': 'linear'}\n",
      "Testing params: {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Training final SVM model with best params: {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Test Set Performance (SVM):\n",
      "Accuracy: 0.9259\n",
      "Precision: 0.9994\n",
      "Recall: 0.9103\n",
      "F1 Score: 0.9528\n",
      "False Positive Rate: 0.0026\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 51270    134]\n",
      " [ 21111 214343]]\n",
      "\n",
      "Inference Time: 33.142426 seconds\n",
      "Peak Memory Usage: 126594.06 KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tracemalloc\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "X_train_selected = X_train_selected.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test_selected = X_test_selected.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# our hyperparameter grid includes both 'linear' and 'rbf' kernels for fair comparison\n",
    "param_grid = {'C': [1, 10], 'kernel': ['linear', 'rbf']}  # RBF added back\n",
    "\n",
    "# 3-fold cross-validation for faster execution\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "best_params, best_f1, lowest_fpr, best_model = None, 0, float('inf'), None\n",
    "\n",
    "def train_fold(C, kernel, X_train_fold, y_train_fold, X_val_fold, y_val_fold):\n",
    "    \"\"\"Train SVM on a single fold.\"\"\"\n",
    "    if kernel == 'linear':\n",
    "        model = LinearSVC(C=C, random_state=42, dual=False)  \n",
    "    else:\n",
    "        model = SVC(C=C, kernel=kernel, random_state=42)\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    f1 = f1_score(y_val_fold, y_val_pred, zero_division=0)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_fold, y_val_pred).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    return accuracy_score(y_val_fold, y_val_pred), f1, fpr\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing params: {params}\")\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(train_fold)(\n",
    "            params['C'], params['kernel'],\n",
    "            X_train_selected.iloc[train], y_train.iloc[train],  \n",
    "            X_train_selected.iloc[val], y_train.iloc[val]\n",
    "        ) for train, val in kf.split(X_train_selected)\n",
    "    )\n",
    "    \n",
    "    mean_acc, mean_f1, mean_fpr = np.mean(results, axis=0)\n",
    "    if mean_f1 > best_f1 or (mean_f1 == best_f1 and mean_fpr < lowest_fpr):\n",
    "        best_f1, lowest_fpr, best_params = mean_f1, mean_fpr, params\n",
    "\n",
    "        with open(\"/kaggle/working/best_params_SVM_final.pkl\", \"wb\") as f:\n",
    "            pickle.dump(best_params, f)\n",
    "\n",
    "if best_params:\n",
    "    print(f\"\\nTraining final SVM model with best params: {best_params}\")\n",
    "    if best_params['kernel'] == 'linear':\n",
    "        best_model = LinearSVC(C=best_params['C'], random_state=42, dual=False)  \n",
    "    else:\n",
    "        best_model = SVC(**best_params, random_state=42)\n",
    "\n",
    "    best_model.fit(X_train_selected, y_train)\n",
    "\n",
    "    with open(\"/kaggle/working/best_model_SVM_final.pkl\", \"wb\") as model_file:\n",
    "        pickle.dump(best_model, model_file)\n",
    "\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    y_test_pred = best_model.predict(X_test_selected)  \n",
    "    end_time = time.time()\n",
    "    current, peak_memory = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    inference_time = end_time - start_time\n",
    "    peak_memory_kb = peak_memory / 1024  \n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0 \n",
    "\n",
    "    print(\"\\nTest Set Performance (SVM):\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "    print(f\"False Positive Rate: {fpr:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"\\nInference Time: {inference_time:.6f} seconds\")\n",
    "    print(f\"Peak Memory Usage: {peak_memory_kb:.2f} KB\")\n",
    "\n",
    "else:\n",
    "    print(\"No trained model found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:12:40.052860Z",
     "iopub.status.busy": "2025-03-30T08:12:40.052407Z",
     "iopub.status.idle": "2025-03-30T08:12:40.607147Z",
     "shell.execute_reply": "2025-03-30T08:12:40.606392Z",
     "shell.execute_reply.started": "2025-03-30T08:12:40.052832Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Performance (Naïve Bayes):\n",
      "Accuracy: 0.7655\n",
      "Precision: 0.9913\n",
      "Recall: 0.7206\n",
      "F1 Score: 0.8346\n",
      "False Positive Rate: 0.0288\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 49922   1482]\n",
      " [ 65778 169676]]\n",
      "\n",
      "Inference Time: 0.206109 seconds\n",
      "Peak Memory Usage: 247613.24 KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tracemalloc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "X_train_selected = X_train_selected.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test_selected = X_test_selected.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_selected, y_train)\n",
    "\n",
    "with open(\"/kaggle/working/best_model_nb.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(nb_model, model_file)\n",
    "\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "y_test_pred = nb_model.predict(X_test_selected)  \n",
    "\n",
    "end_time = time.time()\n",
    "current, peak_memory = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "peak_memory_kb = peak_memory / 1024  \n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Positive Rate\n",
    "\n",
    "print(\"\\nTest Set Performance (Naïve Bayes):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"False Positive Rate: {fpr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(f\"\\nInference Time: {inference_time:.6f} seconds\")\n",
    "print(f\"Peak Memory Usage: {peak_memory_kb:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:13:03.040133Z",
     "iopub.status.busy": "2025-03-30T08:13:03.039816Z",
     "iopub.status.idle": "2025-03-30T08:13:04.694955Z",
     "shell.execute_reply": "2025-03-30T08:13:04.694033Z",
     "shell.execute_reply.started": "2025-03-30T08:13:03.040109Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Performance (Logistic Regression):\n",
      "Accuracy: 0.9537\n",
      "Precision: 0.9959\n",
      "Recall: 0.9475\n",
      "F1 Score: 0.9711\n",
      "False Positive Rate: 0.0177\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 50495    909]\n",
      " [ 12368 223086]]\n",
      "\n",
      "Inference Time: 0.023276 seconds\n",
      "Peak Memory Usage: 7817.40 KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tracemalloc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "X_train_selected = X_train_selected.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test_selected = X_test_selected.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "lr_model = LogisticRegression(solver='liblinear', random_state=42)  \n",
    "lr_model.fit(X_train_selected, y_train)\n",
    "\n",
    "with open(\"/kaggle/working/best_model_lr.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(lr_model, model_file)\n",
    "\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "y_test_pred = lr_model.predict(X_test_selected)  \n",
    "\n",
    "end_time = time.time()\n",
    "current, peak_memory = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "peak_memory_kb = peak_memory / 1024\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  \n",
    "\n",
    "print(\"\\nTest Set Performance (Logistic Regression):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"False Positive Rate: {fpr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(f\"\\nInference Time: {inference_time:.6f} seconds\")\n",
    "print(f\"Peak Memory Usage: {peak_memory_kb:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:13:45.839510Z",
     "iopub.status.busy": "2025-03-30T08:13:45.839168Z",
     "iopub.status.idle": "2025-03-30T08:17:46.304944Z",
     "shell.execute_reply": "2025-03-30T08:17:46.304064Z",
     "shell.execute_reply.started": "2025-03-30T08:13:45.839482Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 18ms/step - accuracy: 0.9530 - loss: 0.1325 - val_accuracy: 0.9934 - val_loss: 0.0376\n",
      "Epoch 2/20\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.9897 - loss: 0.0344 - val_accuracy: 0.8949 - val_loss: 0.3569\n",
      "Epoch 3/20\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.9961 - loss: 0.0161 - val_accuracy: 0.9275 - val_loss: 0.2360\n",
      "Epoch 4/20\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.9965 - loss: 0.0147 - val_accuracy: 0.9632 - val_loss: 0.0862\n",
      "Epoch 5/20\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.9973 - loss: 0.0114 - val_accuracy: 0.9610 - val_loss: 0.0640\n",
      "Epoch 6/20\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.9964 - loss: 0.0137 - val_accuracy: 0.9492 - val_loss: 0.0981\n",
      "\u001b[1m8965/8965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step\n",
      "\n",
      "Test Set Performance (CNN-LSTM):\n",
      "Accuracy: 0.9934\n",
      "Precision: 0.9949\n",
      "Recall: 0.9971\n",
      "F1 Score: 0.9960\n",
      "False Positive Rate: 0.0235\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 50195   1209]\n",
      " [   687 234767]]\n",
      "\n",
      "Inference Time: 35.477214 seconds\n",
      "Peak Memory Usage: 118899.06 KB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import time\n",
    "import tracemalloc\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "X_train_reshaped = X_train_selected.values.reshape(X_train_selected.shape[0], X_train_selected.shape[1], 1)\n",
    "X_test_reshaped = X_test_selected.values.reshape(X_test_selected.shape[0], X_test_selected.shape[1], 1)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_selected.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model.fit(X_train_reshaped, y_train, validation_data=(X_test_reshaped, y_test), \n",
    "          epochs=20, batch_size=64, callbacks=[early_stop])\n",
    "\n",
    "model.save(\"/kaggle/working/best_model_cnn_lstm.h5\")\n",
    "\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test_reshaped)  \n",
    "y_test_pred = (y_test_pred_prob > 0.5).astype(int) \n",
    "end_time = time.time()\n",
    "current, peak_memory = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "peak_memory_kb = peak_memory / 1024 \n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  \n",
    "\n",
    "print(\"\\nTest Set Performance (CNN-LSTM):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "print(f\"False Positive Rate: {fpr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "print(f\"\\nInference Time: {inference_time:.6f} seconds\")\n",
    "print(f\"Peak Memory Usage: {peak_memory_kb:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key takeaways:\n",
    "\n",
    "a) before training, use random forest feature selection method to find highly correlated features, and remove redundant features/apply other strategies like PCA or smthg else\n",
    "\n",
    "b) use binarization strategies as used here, for the features, before training the Tsetlin machine\n",
    "\n",
    "c) the dataset used here, is useful for academic purposes only, and as an exploratory purpose, to test the waters, so to speak. it is too well-labeled, too\n",
    "detailed, and too separable.\n",
    "\n",
    "d) Use CPU, not GPU, cuz the Python Package for Tsetlin machine is only supported by CPU"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2398189,
     "sourceId": 4059918,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6549500,
     "sourceId": 10583425,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 281734,
     "modelInstanceId": 260579,
     "sourceId": 305417,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
